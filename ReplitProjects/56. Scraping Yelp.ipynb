{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **56. Scraping Yelp**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use requests to get the webpage as text. When printing the html, we get back just how much info there is contained in the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://www.yelp.co.uk/search?find_desc=Restaurants&find_loc=San+Francisco%2C+CA%2C+United+States\"\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we pass the html to Beautiful Soup to make more sense of it.\n",
    "\n",
    "html.parser will scan through the HTML recognizing tokens in the text and breaking it down into something more meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.yelp.co.uk/search?find_desc=Restaurants&find_loc=San+Francisco%2C+CA%2C+United+States\"\n",
    "\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back on Yelp, right click the first (non-sponsored) restaurant on the list and inspect it.\n",
    "\n",
    "Right click and copy element for the whole URL, then paste it into your repl as a temporary measure.\n",
    "\n",
    "Inspecting the link gives us clues about what we want beautiful soup to look for. In this case, I want it to look for <a> tags and the class css-1m051bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://www.yelp.co.uk/search?find_desc=Restaurants&find_loc=San+Francisco%2C+CA%2C+United+States\"\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "<a href=\"/biz/marufuku-ramen-san-francisco-5?osq=Restaurants\" class=\"css-1m051bw\" target=\"_blank\" name=\"Marufuku Ramen\" rel=\"noopener\">Marufuku Ramen</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've created a new variable to store the result of the beautiful soup search.\n",
    "\n",
    "`find_all` takes two arguments. The first is the `a` tag. The second is a dictionary that tells it what class to search for. This effectively says 'find me all the `a` tags with this class in them.'\n",
    "I've printed the `len` of those results to see how many I get back.  \n",
    "\n",
    "The most common problem is not identifying the correct tag. Somtimes the text is in the `<a>` tag. Sometimes it's in an `<h>`. Inspect a few links to see what the common class and tag are.  \n",
    "\n",
    "The tag must be the first argument in the `find_all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.yelp.co.uk/search?find_desc=Restaurants&find_loc=San+Francisco%2C+CA%2C+United+States\"\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "myLinks = soup.find_all(\"a\", {\"class\":\"css-1m051bw\"})\n",
    "print(len(myLinks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.yelp.co.uk/search?find_desc=Restaurants&find_loc=San+Francisco%2C+CA%2C+United+States\"\n",
    "\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "myLinks = soup.find_all(\"a\", {\"class\":\"css-1m051bw\"})\n",
    "\n",
    "print(len(myLinks))\n",
    "\n",
    "for link in myLinks:\n",
    "    print(link.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see that the same tag has been used in the info about the location and category, so they're included in the results.\n",
    "\n",
    "I'm going to use a loop counter to start the print loop at item 3 to leave them off the output.\n",
    "I'm also going to include the link to the restaurant in the output by using a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.yelp.co.uk/search?find_desc=Restaurants&find_loc=San+Francisco%2C+CA%2C+United+States\"\n",
    "\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "myLinks = soup.find_all(\"a\", {\"class\":\"css-1m051bw\"})\n",
    "\n",
    "counter = 0\n",
    "for link in myLinks:\n",
    "  if counter > 1:\n",
    "    print(link.text)\n",
    "    print(link[\"href\"])\n",
    "  counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add an fstring. The web links are local, they aren't relative to the site I'm using, so I've formatted the print(link[\"href\"]) as an fString to add the relative address (that I found in the Yelp inspect code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.yelp.co.uk/search?find_desc=Restaurants&find_loc=San+Francisco%2C+CA%2C+United+States\"\n",
    "\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "myLinks = soup.find_all(\"a\", {\"class\":\"css-1m051bw\"})\n",
    "\n",
    "counter = 0\n",
    "for link in myLinks:\n",
    "  if counter > 1:\n",
    "    print(link.text)\n",
    "    print(f'https://www.yelp.com{link[\"href\"]}')\n",
    "  counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Scraping headlines from Hacker News**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Headlines must include the words 'replit', 'python', 'apple', or 'microsoft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://news.ycombinator.com/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "myLinks = soup.find_all(\"span\", {\"class\":\"titleline\"})\n",
    "\n",
    "things = [\"replit\", \"python\", \"apple\", \"microsoft\"]\n",
    "\n",
    "for link in myLinks:\n",
    "  text = link.text\n",
    "  # splits the string into a list to iterate over\n",
    "  textList = text.split()\n",
    "  for word in textList:\n",
    "    if word.lower() in things:\n",
    "      print(text)a"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
