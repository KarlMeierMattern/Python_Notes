# ML Models  

## ML regression models  
- Regression algorithms are used to predict a continuous outcome (y) using independent variables (x).  
- Where there are multuple input variables it is called a multivariate regression model.  
- The dependent variable (y) must be numeric.  
- For example, predicting the rent of a house based on its size, the number of bedrooms, and whether it is fully furnished.  

## Regresssion metrics  
- A common misconception is that a regression model can be evaluated using a metric like accuracy.  
- Accuracy is a metric used to assess the performance of classification models.  
- Regression models, on the other hand, are evaluated using metrics such as MAE (Mean Absolute Error), MSE (Mean Squared Error), and RMSE (Root Mean Squared Error).  

### Mean absolute error  
- Calculates the sum of the difference between all true and predicted values, and divides this by the total number of observations.  

### Mean squared error  
- Calculates the sum of the difference between all true and predicted values squared, and divides this by the total number of observations.  

### Root mean squared error  
- Calculated as the square root of the mean squared error.  
- One advantage of the RMSE over its MSE is that the error is returned in the same unit of the variable we are predicting.  

## Linear regression  
- `y = mx + c` there are infinite ways to draw this line based on `m` and `c`
- Line of best fit/least squares regression line is found by *minimizing the sum of squared distance between the true and predicted values*.  

## Ridge regression  
- Technique used to keep a regression model’s coefficients as low as possible.  
- One problem with a simple linear regression model is that its coefficients can become large, which makes the model more sensitive to inputs. This can lead to overfitting.  
- A perfect line on a trainining data set will likely not generalize well to test data. This phenomenon is called overfitting.  
- A model that is highly complex will pick up on unnecessary nuances of the training dataset that aren’t reflected in the real world. This model will perform extremely well on training data but will underperform on datasets outside what it was trained on.  
- A linear regression model with large coefficients is prone to overfitting.  
- Ridge regression is a *regularization technique* that will force the algorithm to choose smaller coefficients by penalizing its loss function to include an additional cost.  

## Lasso regression  
- Extension of linear regression that shrinks model coefficients by adding a penalty term to its cost function.  
- The biggest difference between ridge and lasso regression is that in ridge regression, while  model coefficients can shrink towards zero, they never actually become zero. In lasso regression, it is possible for model coefficients to become zero.  
- Due to this, lasso regression can also be used as a `feature selection technique`, since variables with low importance can have coefficients that reach zero and will be removed entirely from the model.  


## sklearn  
- These import statements allow you to use different scikit-learn functionalities, such as loading datasets, splitting data, preprocessing, building models, and evaluating model performance.  

    from sklearn import datasets  

> For loading example datasets  

    from sklearn.model_selection import train_test_split  

> For splitting data into training and testing sets  

    from sklearn.preprocessing import StandardScaler  

> For feature scaling  

    from sklearn.linear_model import LogisticRegression  

> For logistic regression model

    from sklearn.tree import DecisionTreeClassifier  

> For decision tree classifier

    from sklearn.metrics import accuracy_score  

> For evaluating model accuracy  

---

## ML classification models  
- We use classification algorithms to predict a discrete outcome (y) using independent variables (x).  
- The dependent variable is always a class or category.  
- For example, predicting whether a patient is likely to develop heart disease based on their risk factors is a classification problem.  

