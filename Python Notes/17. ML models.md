# ML Models  
Link to source https://www.datacamp.com/blog/machine-learning-models-explained  
1. ML regression models  
- Liner regression  
- Ridge regresssion  
- Lasso regression  
2. ML classification models  
- Logistic regression  
- K-nearest neighbours  
3. ML tree-based models  
- Decision trees  
- Random forests  
4. ML clustering  
- K-means clustering  

---

## ML regression models  
- Regression algorithms are used to predict a continuous outcome (y) using independent variables (x).  
- Where there are multuple input variables it is called a multivariate regression model.  
- The dependent variable (y) must be numeric.  
- For example, predicting the rent of a house based on its size, the number of bedrooms, and whether it is fully furnished.  

### Linear regression  
- `y = mx + c` there are infinite ways to draw this line based on `m` and `c`
- Line of best fit/least squares regression line is found by *minimizing the sum of squared distance between the true and predicted values*.  

### Ridge regression  
- Technique used to keep a regression model’s coefficients as low as possible.  
- One problem with a simple linear regression model is that its coefficients can become large, which makes the model more sensitive to inputs. This can lead to overfitting.  
- A perfect line on a trainining data set will likely not generalize well to test data. This phenomenon is called overfitting.  
- A model that is highly complex will pick up on unnecessary nuances of the training dataset that aren’t reflected in the real world. This model will perform extremely well on training data but will underperform on datasets outside what it was trained on.  
- A linear regression model with large coefficients is prone to overfitting.  
- Ridge regression is a *regularization technique* that will force the algorithm to choose smaller coefficients by penalizing its loss function to include an additional cost.  

### Lasso regression  
- Extension of linear regression that shrinks model coefficients by adding a penalty term to its cost function.  
- The biggest difference between ridge and lasso regression is that in ridge regression, while  model coefficients can shrink towards zero, they never actually become zero. In lasso regression, it is possible for model coefficients to become zero.  
- Due to this, lasso regression can also be used as a `feature selection technique`, since variables with low importance can have coefficients that reach zero and will be removed entirely from the model.  

### Regresssion metrics  
- A common misconception is that a regression model can be evaluated using a metric like accuracy.  
- Accuracy is a metric used to assess the performance of classification models.  
- Regression models, on the other hand, are evaluated using metrics such as MAE (Mean Absolute Error), MSE (Mean Squared Error), and RMSE (Root Mean Squared Error).  

#### Mean absolute error  
- Calculates the sum of the difference between all true and predicted values, and divides this by the total number of observations.  

#### Mean squared error  
- Calculates the sum of the difference between all true and predicted values squared, and divides this by the total number of observations.  

#### Root mean squared error  
- Calculated as the square root of the mean squared error.  
- One advantage of the RMSE over its MSE is that the error is returned in the same unit of the variable we are predicting.  

---

## ML classification models  
- We use classification algorithms to predict a discrete outcome (y) using independent variables (x).  
- The dependent variable is always a class or category.  
- For example, predicting whether a patient is likely to develop heart disease based on their risk factors is a classification problem.  
- If there are only two possible outcomes (e.g. Yes and No), this is called a binary classification problem.  
- Other examples of `binary classification` problems include classifying whether email is spam or legitimate, customer churn prediction, and deciding whether to provide someone a loan.  
- `Multiclass classification` problems incorporate three or more possible outcomes, such as weather forecasting or distinguishing between different animal species.  

### Logistic regression  
- Predicts the probability of an event taking place.  
- Unlike linear regression, logistic regression is modelled with an s-shaped curve, which is known as a logistic function.  
- The model predicts probability of an event occurring between 0 and 1. As such, there is a lower and upper bounds, unlike linear regression.  

#### Example  
- Spam email: if the text contains little to no suspicious keywords, then the probability of it being spam will be low and close to 0, conversely many suspicious keywords will have a high probability of being spam, close to 1.  
- This probability is then turned into a classification outcome.  
- Data points with a probability >= 0.5 of being spam are classified as spam and the logistic regression model will return a classification outcome of 1.  
- Data points with a probability < 0.5 of being spam are classified by the model as “Not Spam” and will return a classification outcome of 0.  
- For binary classification problems, the default threshold of a logistic regression model is 0.5, which means that data points with a higher probability than 0.5 will automatically be assigned a label of 1. This threshold value can be manually changed depending on your use case to achieve better results.  
- In linear regression we found the line of best fit by minimizing the sum of squared error between the predicted and true values. In logistic regression, however, the coefficients are estimated using a technique called *maximum likelihood estimation* instead of least squares.  

### K-nearest neighbours (KNN)  
- Classification algorithm that classifies a data point based on what group the data points nearest to it belong to.  

#### Example  
The K-Nearest Neighbors algorithm works like this:  
- Step 1: The model first stores all the training data.  
- Step 2: Then, it calculates the distance from the new data point to all points in the dataset.  
- Step 3: The model sorts these data points based on their distance to the new data point.  
- Step 4: The new data point is assigned to the class of its nearest neighbors depending on the value of “k.”  
- If we assign k as 1, the model looks at only one closest neighbor to the data point and assigns the data point to that class.  
- Choosing different values of k will impact what class the new point is assigned to.  

### Classification metrics  
- While accuracy is the most used metric, it is not always the most reliable.  

#### Accuracy  
- The fraction of correct predictions made by the machine learning model.  

#### Precision  
- Calculates the quality of positive predictions made by the model.  

#### Recall  
- Used to calculate the quality of negative predictions made by the model.  

#### Example  
- There is a rare, fatal disease that affects a fraction of the population. 95% of the patients in a hospital’s database do not have the disease, while only 5% do. 
- If the ML algorithm predicts that nobody has the disease, then the training accuracy of this model will be 95%. Despite the high accuracy, we know this is not a good model.  
- Precision, or specificity, tells us the ability of the model to correctly identify people without the disease.  
- Recall, or sensitivity, tells us how well the model identifies people with the disease.  
- A “good” precision and recall value is subjective and depends on your use case.  
- In this disease prediction scenario, we always want to identify people with the disease, even if this comes with the risk of a false positive. Here, we will build the model to have higher recall than precision.  
- However, if we were to build a model that prevents malicious actors from entering an e-commerce website, we might want higher precision since blocking legitimate users will lead to a decline in sales.
- We often use a metric called the `F1-Score` to find the harmonic mean of a classifier’s precision and recall. Simply put, the F1-Score combines precision and recall into a single metric by computing their average.  
- AUC, or Area Under the Curve, is another popular metric used to measure the performance of a classification model. An algorithm’s AUC tells us about its ability to distinguish between positive and negative classes.  

---

## ML tree-based models  
- Tree-based models are *supervised* machine learning algorithms that construct a tree-like structure to make predictions.  
- They can be used for both classification and regression problems.  
- A tree's depth is a measure of how many splits it makes before coming to a prediction.  
- https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html  

### Decision trees  
- This model allows us to continuously split the dataset based on specific parameters until a final decision is made.  
- The decision tree will choose a variable to split on first based on a metric called `entropy`.  
- Entropy is a measure of disorder or impurity in a node. Thus, a node with more variable composition, such as Pass and Fail would be considered to have higher entropy than a node which has only pass or only fail.  
- It will stop splitting when a `pure split` is obtained, i.e., when all the data points belong to a single class.  
- The structure is created based on a metric called `information gain`. The best possible decision tree is one with the highest information gain.  
- Decision trees are prone to overfitting if left to grow completely. This is because they are designed to split perfectly on all samples of the training dataset, which makes them unable to generalize well to external data.  

### Random forests  
- Created by combining the predictions made by multiple decision tree models and returning a single output.  
- Step 1: The rows and variables of the dataset are randomly sampled with replacement. Multiple decision trees are then created and trained on each data sample.  
- Step 2: The predictions made by all these decision trees are combined to come up with a single output. For instance, if 3 separate decision trees were trained and 2 of them predicted “Yes” while 1 predicted “No,” then the final outcome of the random forest algorithm would be “Yes.”  
- In case of a regression problem, the outcome will be the average prediction of all decision trees.  
- One of the biggest advantages of the random forest algorithm is that it generalizes well, since it combines the output of multiple decision trees that are trained on a subset of features.  

---

## ML clustering models  
- *Unsupervised* learning approach.  
- Clustering is the task of creating a group of objects that are similar to each other but different from others.  
- Business use cases include: recommending movies to users with similar viewing patterns on a video streaming site, anomaly detection, and customer segmentation.  

### K-means clustering  
- Used to group similar objects together in data.  
- Step 1: Initially, each observation will be assigned to a cluster at random. A centroid will then be computed for each cluster.  
- Step 2: The distance of each data point to the centroid is measured, and each point is assigned to the nearest centroid.  
- Step 3: The centroid of the new cluster is then recalculated, and data points will be reassigned accordingly.  
- Step 4: This process is repeated until data points are no longer being reassigned.  

---

## The steps to building and using a model  
- Define: What type of model will it be? A decision tree? Some other type of model?  
- Fit: Capture patterns from provided data. This is the heart of modeling.  
- Predict: Just what it sounds like.  
- Evaluate: Determine how accurate the model's predictions are.  

## How models works  
- Fitting/training the model is when we use data to decide how to split the data into categories, and then, based on that category, what the prediction would be.  
- After the model has been fit, you can apply it to new data to predict prices of additional homes.  
- You can capture more factors using a tree that has more `splits`. These are called "deeper" trees.  
- The point at the bottom where we make a prediction is called a `leaf`.  

## scikit-learn    
- These import statements allow you to use different scikit-learn functionalities, such as loading datasets, splitting data, preprocessing, building models, and evaluating model performance.  

    from sklearn import datasets  

> For loading example datasets  

    from sklearn.model_selection import train_test_split  

> For splitting data into training and testing sets  

    from sklearn.preprocessing import StandardScaler  

> For feature scaling  

    from sklearn.linear_model import LogisticRegression  

> For logistic regression model

    from sklearn.tree import DecisionTreeClassifier  

> For decision tree classifier

    from sklearn.metrics import accuracy_score  

> For evaluating model accuracy  

### Model prediction    
- Store the `prediction target` as `y`.  
- Store the `features`, containing a list of columns, as `X`.  

        import pandas as pd

        melbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv'
        melbourne_data = pd.read_csv(melbourne_file_path) 

        filtered_melbourne_data = melbourne_data.dropna(axis=0)

        y = filtered_melbourne_data.Price
        melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', 'YearBuilt', 'Lattitude', 'Longtitude']
        X = filtered_melbourne_data[melbourne_features]

        from sklearn.tree import DecisionTreeRegressor
        melbourne_model = DecisionTreeRegressor(random_state=1)
        melbourne_model.fit(X, y)
        melbourne_model.predict(X)

### Model validation  
- Measures the quality of the model.  
- In most applications, the relevant measure of model quality is predictive accuracy.  
- The mistake is to make predictions with training data and compare those predictions to the target values in the training data.  
- The most straightforward way to do this is to exclude some data from the model-building process, and then use those to test the model's accuracy on data it hasn't seen before. This data is called *validation* data.  
- The best model will have the lowest MAE.  

#### The wrong way  
- Using *in-sample* data.  
- We used a single "sample" of houses for both building the model and evaluating it.  

        from sklearn.metrics import mean_absolute_error

        predicted_home_prices = melbourne_model.predict(X)
        mean_absolute_error(y, predicted_home_prices)

#### The correct way  
- Using *out-of-sample* data.  
- `train_test_split` is used to break up the data into two pieces.  
- We'll use some of that data as training data to fit the model, and we'll use the other data as validation data to calculate `mean_absolute_error`.

        from sklearn.model_selection import train_test_split

        train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 1)
        melbourne_model = DecisionTreeRegressor(random_state = 1)
        melbourne_model.fit(train_X, train_y)

        val_predictions = melbourne_model.predict(val_X)

        print("The predictions are", melbourne_model.predict(val_X.head()))
        print("The actual data is", y.head().tolist())

        print(mean_absolute_error(val_y, val_predictions))

---

## Underfitting & overfitting  
- When we divide the houses amongst many leaves, we also have fewer houses in each leaf. Leaves with very few houses will make predictions that are quite close to those homes' actual values, but they may make very unreliable predictions for new data (because each prediction is based on only a few houses).  
- This is a phenomenon called *overfitting*, where a model matches the training data almost perfectly, but does poorly in validation and other new data.  
- *Overfitting*: capturing spurious patterns that won't recur in the future, leading to less accurate predictions.  
- On the flip side, if we make our tree very shallow, it doesn't divide up the houses into very distinct groups.  
- When a model fails to capture important distinctions and patterns in the data, so it performs poorly even in training data, that is called *underfitting*.  
- *Underfitting*: failing to capture relevant patterns, leading to less accurate predictions.  
- There are a few alternatives for controlling the tree depth, and many allow for some routes through the tree to have greater depth than other routes.  
- We use *validation* data, which isn't used in model training, to measure a candidate model's accuracy. This lets us try many candidate models and keep the best one.  
- `max_leaf_nodes` argument provides a very sensible way to control overfitting vs underfitting.  

#### Example  

    from sklearn.metrics import mean_absolute_error
    from sklearn.tree import DecisionTreeRegressor

    def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):
        model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)
        model.fit(train_X, train_y)
        preds_val = model.predict(val_X)
        mae = mean_absolute_error(val_y, preds_val)
        return(mae)

    for max_leaf_nodes in [5, 50, 500, 5000]:
        my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)
        print("Max leaf nodes: %d  \t\t Mean Absolute Error:  %d" %(max_leaf_nodes, my_mae))

> The data is loaded into train_X, val_X, train_y and val_y using the code seen previously.  
> Here we are comparing MAE with differing values for max_leaf_nodes.  

---

#### Full example  

    import pandas as pd
    from sklearn.metrics import mean_absolute_error
    from sklearn.model_selection import train_test_split
    from sklearn.tree import DecisionTreeRegressor

    iowa_file_path = '../input/home-data-for-ml-course/train.csv'

    home_data = pd.read_csv(iowa_file_path)
    y = home_data.SalePrice
    features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']
    X = home_data[features]

    train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)

    iowa_model = DecisionTreeRegressor(random_state=1)
    iowa_model.fit(train_X, train_y)

    val_predictions = iowa_model.predict(val_X)
    val_mae = mean_absolute_error(val_predictions, val_y)
    print(f"Validation MAE: {val_mae:,.0f}")

    def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):
        model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)
        model.fit(train_X, train_y)
        preds_val = model.predict(val_X)
        mae = mean_absolute_error(val_y, preds_val)
        return(mae)

    candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]
    scores = {leaf_size: get_mae(leaf_size, train_X, val_X, train_y, val_y) for leaf_size in candidate_max_leaf_nodes}
    best_tree_size = min(scores, key=scores.get)

    final_model = DecisionTreeRegressor(max_leaf_nodes=best_tree_size, random_state=1)

    final_model.fit(X, y)

> Because we now know the `best_tree_size`, with the lowest MAE (being 100), we will make the model more accruate by using all of the data with that tree size. This means we won't save any validation data.  
> As such we use `final_model.fit(X,y)` and not `final_model.fit(train_X,train_y)`.  

---

## Random forests  
- The random forest uses many trees, and it makes a prediction by averaging the predictions of each component tree. It generally has much better predictive accuracy than a single decision tree and it works well with default parameters.  

        import pandas as pd
            
        melbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv'
        melbourne_data = pd.read_csv(melbourne_file_path) 
        melbourne_data = melbourne_data.dropna(axis=0)
        y = melbourne_data.Price
        melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', 'YearBuilt', 'Lattitude', 'Longtitude']
        X = melbourne_data[melbourne_features]

        from sklearn.model_selection import train_test_split

        train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0, n_estimators = 20)

        from sklearn.ensemble import RandomForestRegressor
        from sklearn.metrics import mean_absolute_error

        forest_model = RandomForestRegressor(random_state=1)
        forest_model.fit(train_X, train_y)
        melb_preds = forest_model.predict(val_X)
        print(mean_absolute_error(val_y, melb_preds))

> `n_estimators` sets the number of decision trees to be included in the random forest, in this case 20.  
> Increasing the number of estimators can improve the performance of the random forest by reducing the variance of the predictions.  
> However, it also increases the computational cost, as more decision trees need to be trained and evaluated.  

---

## Missing values  

### Drop columns with missing values  

    cols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()] # Your code here

    reduced_X_train = X_train.drop(cols_with_missing, axis=1)
    reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)

> Identifies and creates a list of columns with missing values.  
> Drops those columns from both the training and validation datasets.  

### Imputation  

    from sklearn.impute import SimpleImputer

    my_imputer = SimpleImputer()
    imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))
    imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))

    imputed_X_train.columns = X_train.columns
    imputed_X_valid.columns = X_valid.columns

    print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))

> Imputation removed column names so we put them back.  

### Compare approaches  

    from sklearn.ensemble import RandomForestRegressor
    from sklearn.metrics import mean_absolute_error

    def score_dataset(X_train, X_valid, y_train, y_valid):
        model = RandomForestRegressor(n_estimators=100, random_state=0)
        model.fit(X_train, y_train)
        preds = model.predict(X_valid)
        return mean_absolute_error(y_valid, preds)

> This is a generic function that you can reuse to compare different approaches to dealing with missing values.  
> The approach that results in the lowest MAE should be chosen.  

    score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid)

> We could use this function to check the MAE of the approach above where we dropped missing columns.  

---

## Categorical variables  


## Pipelines  


## Cross-validation  


## XGBoost  


## Leakage  



